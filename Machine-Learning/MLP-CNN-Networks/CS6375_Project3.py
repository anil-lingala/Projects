# -*- coding: utf-8 -*-
"""CS6375_Project3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SZq8dCZm3QT40Cat9KdArmiBkVdpq6pI

# CS 6375 Project 3
Name: Anil Lingala

Course: CS 6375.001

In this project, you will implement and evaluate Multilayer Perceptrons (MLPs) and Convolutional Neural Networks (CNNs) on two well-known image datasets: MNIST and CIFAR-10

### Environment Setup
This project implements and evaluates **Multilayer Perceptrons (MLPs)** and **Convolutional Neural Networks (CNNs)** on two benchmark datasets: **MNIST** and **CIFAR-10**, using **PyTorch** (`torchvision`).  
We ensure reproducibility by setting fixed random seeds and managing results in organized directories.  
*(Ref: “You will utilize PyTorch for implementation. Code must compile and reproduce results exactly.”)*
"""

# Environment and imports
import os, random, time, json, math
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
from dataclasses import dataclass, asdict

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
RESULTS_DIR = "./results_project3"
os.makedirs(RESULTS_DIR, exist_ok=True)
print("Device:", DEVICE)

# Experiment settings
FAST_DEBUG = False
EPOCHS_MNIST = 10 if not FAST_DEBUG else 2
EPOCHS_CIFAR = 12 if not FAST_DEBUG else 2
PATIENCE = 3
REPEATS_PER_CONFIG = 1 if not FAST_DEBUG else 1
NUM_TRIALS_PER_ARCH = 10 if not FAST_DEBUG else 2

LR_CHOICES = [1e-2, 1e-3, 1e-4]
BATCH_CHOICES = [32, 64, 128]
OPTIMIZERS = ["sgd", "adam"]
DROPOUTS = [0.0, 0.2, 0.5]

# Function that sets random seeds for reproducibility across libs
def set_seed(seed: int = 1337):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = False

set_seed(1337)

"""# Datasets and Preprocessing

• Use PyTorch (torchvision) to load MNIST and CIFAR-10 datasets.

• Normalize pixel values to [0,1] or use standard normalization.

• Clearly document your preprocessing steps.
"""

# Function that prepares datasets and deterministic train/val splits
def prepare_datasets():
    mnist_transform = transforms.Compose([transforms.ToTensor()])
    cifar_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465),
                             (0.2023, 0.1994, 0.2010))
    ])

    mnist_trainval = datasets.MNIST(root="./data", train=True, download=True, transform=mnist_transform)
    mnist_test = datasets.MNIST(root="./data", train=False, download=True, transform=mnist_transform)

    cifar_trainval = datasets.CIFAR10(root="./data", train=True, download=True, transform=cifar_transform)
    cifar_test = datasets.CIFAR10(root="./data", train=False, download=True, transform=cifar_transform)

    set_seed(1337)
    mnist_train, mnist_val = random_split(mnist_trainval, [50_000, 10_000], generator=torch.Generator().manual_seed(1337))
    set_seed(1337)
    cifar_train, cifar_val = random_split(cifar_trainval, [45_000, 5_000], generator=torch.Generator().manual_seed(1337))

    return (mnist_train, mnist_val, mnist_test), (cifar_train, cifar_val, cifar_test)

mnist_data, cifar_data = prepare_datasets()
print("MNIST sizes:", len(mnist_data[0]), len(mnist_data[1]), len(mnist_data[2]))
print("CIFAR-10 sizes:", len(cifar_data[0]), len(cifar_data[1]), len(cifar_data[2]))

"""### Part 1: Multilayer Perceptrons (MLPs)
We evaluate three distinct fully-connected architectures:  
1. **Shallow** – 1 hidden layer (e.g., 128 units)  
2. **Medium-depth** – 3 hidden layers (e.g., [512, 256, 128])  
3. **Deep** – ≥5 hidden layers (custom choice)  
Each MLP flattens image inputs and uses ReLU activations and dropout regularization.  
*(Ref: “Implement MLPs that accept flattened images from MNIST and CIFAR-10. Evaluate at least three distinct architectures.”)*

"""

# Function that defines a configurable MLP classifier
class MLP(nn.Module):
    def __init__(self, input_dim=784, num_classes=10, hidden_sizes=(128,), dropout=0.0):
        super().__init__()
        layers = []
        prev = input_dim
        for h in hidden_sizes:
            layers.extend([nn.Linear(prev, h), nn.ReLU(), nn.Dropout(p=dropout)])
            prev = h
        layers.append(nn.Linear(prev, num_classes))
        self.layers = nn.Sequential(*layers)

    def forward(self, x):
        x = x.view(x.size(0), -1)
        return self.layers(x)

"""### Part 2: Convolutional Neural Networks (CNNs)
We implement three CNN variants for image classification:  
1. **Baseline CNN** – two convolutional layers with pooling and a fully-connected output.  
2. **Enhanced CNN** – adds Batch Normalization and Dropout.  
3. **Deeper CNN** – at least three convolutional blocks with pooling, normalization, and dropout.  
All CNNs use ReLU activations and end with a softmax (via `CrossEntropyLoss`).  
*(Ref: “Evaluate at least three distinct CNN architectures.”)*

"""

# Function that defines a 2-block baseline CNN
class CNNBaseline(nn.Module):
    def __init__(self, in_channels=1, num_classes=10, dropout=0.0):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(in_channels, 32, 3, padding=1), nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),
            nn.MaxPool2d(2),
        )
        self.dropout = nn.Dropout(p=dropout)
        feat_dim = 64 * (7 * 7 if in_channels == 1 else 8 * 8)
        self.classifier = nn.Linear(feat_dim, num_classes)

    def forward(self, x):
        x = self.features(x)
        x = self.dropout(x)
        x = torch.flatten(x, 1)
        return self.classifier(x)

# Function that defines a batch-normalized CNN with dropout
class CNNEnhanced(nn.Module):
    def __init__(self, in_channels=1, num_classes=10, dropout=0.5):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(in_channels, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),
            nn.MaxPool2d(2),
        )
        self.dropout = nn.Dropout(p=dropout)
        feat_dim = 64 * (7 * 7 if in_channels == 1 else 8 * 8)
        self.classifier = nn.Linear(feat_dim, num_classes)

    def forward(self, x):
        x = self.features(x)
        x = self.dropout(x)
        x = torch.flatten(x, 1)
        return self.classifier(x)

# Function that defines a deeper CNN with three conv stages
class CNNDeeper(nn.Module):
    def __init__(self, in_channels=1, num_classes=10, dropout=0.5):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(in_channels, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),
            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),
            nn.MaxPool2d(2),
        )
        self.dropout = nn.Dropout(p=dropout)
        feat_dim = 128 * (7 * 7 if in_channels == 1 else 8 * 8)
        self.classifier = nn.Linear(feat_dim, num_classes)

    def forward(self, x):
        x = self.features(x)
        x = self.dropout(x)
        x = torch.flatten(x, 1)
        return self.classifier(x)

# Function that stores training hyperparameters as a dataclass
@dataclass
class TrainConfig:
    learning_rate: float
    batch_size: int
    optimizer_name: str
    dropout_rate: float
    epochs: int
    patience: int
    repeats: int

# Function that builds an optimizer from a string name
def make_optimizer(parameters, optimizer_name: str, learning_rate: float):
    name = optimizer_name.lower()
    if name == "sgd":
        return torch.optim.SGD(parameters, lr=learning_rate, momentum=0.9)
    if name == "adam":
        return torch.optim.Adam(parameters, lr=learning_rate)
    raise ValueError(f"Unknown optimizer: {optimizer_name}")

# Function that computes classification accuracy for a dataloader
def compute_accuracy(model, loader, device=DEVICE):
    model.eval()
    total, correct = 0, 0
    with torch.no_grad():
        for inputs, targets in loader:
            inputs, targets = inputs.to(device), targets.to(device)
            logits = model(inputs)
            predictions = logits.argmax(dim=1)
            correct += (predictions == targets).sum().item()
            total += targets.size(0)
    return correct / total

"""### ⏹ Early Stopping & Model Selection
We apply early stopping when validation accuracy plateaus or decreases.  
The best-performing configuration (highest validation accuracy) is selected and its state saved.  
*(Ref: “You may stop training when validation accuracy plateaus … Report the stopping epoch if you use early stopping.”)*

"""

# Function that trains a model with early stopping and returns best val and runtime
def train_one_run(model, train_loader, val_loader, config: TrainConfig, device=DEVICE):
    criterion = nn.CrossEntropyLoss()
    optimizer = make_optimizer(model.parameters(), config.optimizer_name, config.learning_rate)

    best_val = -1.0
    best_state = None
    epochs_without_improvement = 0
    start_time = time.time()

    for epoch in range(config.epochs):
        model.train()
        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            logits = model(inputs)
            loss = criterion(logits, targets)
            loss.backward()
            optimizer.step()

        val_acc = compute_accuracy(model, val_loader, device)
        if val_acc > best_val:
            best_val = val_acc
            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}
            epochs_without_improvement = 0
        else:
            epochs_without_improvement += 1
            if config.patience > 0 and epochs_without_improvement >= config.patience:
                break

    if best_state is not None:
        model.load_state_dict(best_state)

    minutes = (time.time() - start_time) / 60.0
    return best_val, minutes

# Function that evaluates a trained model on the test split
def evaluate_on_test(model, test_loader, device=DEVICE):
    return compute_accuracy(model, test_loader, device)

# Function that samples random hyperparameter configurations
def sample_random_configs(num_trials: int, epochs: int, repeats: int, patience: int):
    configs = []
    for _ in range(num_trials):
        configs.append(TrainConfig(
            learning_rate=random.choice(LR_CHOICES),
            batch_size=random.choice(BATCH_CHOICES),
            optimizer_name=random.choice(OPTIMIZERS),
            dropout_rate=random.choice(DROPOUTS),
            epochs=epochs,
            patience=patience,
            repeats=repeats
        ))
    return configs

# Function that builds a dataloader
def build_loader(dataset, batch_size: int, shuffle: bool):
    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=2, pin_memory=True)

"""###  Hyperparameter Tuning (Validation-Based)
For each architecture and dataset, we perform **validation-based hyperparameter tuning** over key parameters:  
- Learning rate {0.01, 0.001, 0.0001}  
- Batch size {32, 64, 128}  
- Optimizer (SGD vs. Adam)  
- Dropout {0.0, 0.2, 0.5}  

Instead of exhaustively testing all 36 combinations, we explore ~10 meaningful configurations per architecture (`NUM_TRIALS_PER_ARCH = 10`) using random search.  
Each run records validation accuracy, standard deviation, and runtime in CSV files.  
*(Ref: “Explore at least 10–12 meaningful configurations for each architecture … Select the best configuration based on validation accuracy.”)*

### Final Retraining and Test Evaluation
After selecting the best configuration, the model is retrained on the **combined training + validation sets** and evaluated on the held-out **test set**.  
Final test accuracy is saved to JSON and displayed for each architecture.  
*(Ref: “Retrain the final model on the combined training and validation data, and report test accuracy on the designated test set.”)*
"""

# Function that runs random search for one architecture and saves CSV/JSON results
def run_random_search(dataset_tag, arch_tag, model_builder, train_set, val_set, test_set,
                      in_channels, epochs, num_trials, repeats, patience,
                      is_mlp=False, input_dim=None):
    import pandas as pd

    result_rows = []
    best_val, best_cfg, best_state = -1.0, None, None

    configs = sample_random_configs(num_trials, epochs, repeats, patience)

    for config in configs:
        if is_mlp:
            model = model_builder(input_dim, 10, config.dropout_rate).to(DEVICE)
        else:
            model = model_builder(in_channels, 10, config.dropout_rate).to(DEVICE)

        train_loader = build_loader(train_set, config.batch_size, True)
        val_loader = build_loader(val_set, config.batch_size, False)

        validation_scores, runtimes = [], []
        for r in range(config.repeats):
            if r > 0:
                if is_mlp:
                    model = model_builder(input_dim, 10, config.dropout_rate).to(DEVICE)
                else:
                    model = model_builder(in_channels, 10, config.dropout_rate).to(DEVICE)
            set_seed(1337 + r)
            score, minutes = train_one_run(model, train_loader, val_loader, config)
            validation_scores.append(score)
            runtimes.append(minutes)

        mean_val = float(np.mean(validation_scores))
        std_val = float(np.std(validation_scores)) if len(validation_scores) > 1 else 0.0
        mean_minutes = float(np.mean(runtimes))

        result_rows.append([
            arch_tag, config.learning_rate, config.batch_size, config.optimizer_name,
            config.dropout_rate, mean_val, std_val, mean_minutes
        ])

        if mean_val > best_val:
            best_val = mean_val
            best_cfg = config
            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}

    df = pd.DataFrame(result_rows, columns=[
        "Architecture", "Learning rate", "Batch size", "Optimizer", "Dropout",
        "Validation Acc", "±std", "Runtime (min)"
    ])
    csv_path = os.path.join(RESULTS_DIR, f"{dataset_tag}_{arch_tag}_validation_results.csv")
    df.to_csv(csv_path, index=False)

    if is_mlp:
        final_model = model_builder(input_dim, 10, best_cfg.dropout_rate).to(DEVICE)
    else:
        final_model = model_builder(in_channels, 10, best_cfg.dropout_rate).to(DEVICE)

    combined_train = torch.utils.data.ConcatDataset([train_set, val_set])
    full_loader = build_loader(combined_train, best_cfg.batch_size, True)
    test_loader = build_loader(test_set, best_cfg.batch_size, False)

    _ = train_one_run(final_model, full_loader, test_loader, TrainConfig(
        learning_rate=best_cfg.learning_rate,
        batch_size=best_cfg.batch_size,
        optimizer_name=best_cfg.optimizer_name,
        dropout_rate=best_cfg.dropout_rate,
        epochs=best_cfg.epochs,
        patience=0,
        repeats=1
    ))
    test_acc = evaluate_on_test(final_model, test_loader)

    with open(os.path.join(RESULTS_DIR, f"{dataset_tag}_{arch_tag}_final_test.json"), "w") as f:
        json.dump({
            "dataset": dataset_tag,
            "architecture": arch_tag,
            "best_config": asdict(best_cfg),
            "best_val_acc": best_val,
            "test_acc": test_acc
        }, f, indent=2)

    return df, test_acc, best_cfg

# Function that returns MLP architecture presets
def get_mlp_presets():
    return {
        "MLP_shallow": lambda input_dim, num_classes, d: MLP(input_dim, num_classes, (128,), d),
        "MLP_medium":  lambda input_dim, num_classes, d: MLP(input_dim, num_classes, (512, 256, 128), d),
        "MLP_deep":    lambda input_dim, num_classes, d: MLP(input_dim, num_classes, (512, 256, 256, 128, 64), d),
    }

# Function that returns CNN architecture presets
def get_cnn_presets():
    return {
        "CNN_baseline": lambda in_ch, num_classes, d: CNNBaseline(in_ch, num_classes, d),
        "CNN_enhanced": lambda in_ch, num_classes, d: CNNEnhanced(in_ch, num_classes, d),
        "CNN_deeper":   lambda in_ch, num_classes, d: CNNDeeper(in_ch, num_classes, d),
    }

# Function that runs all MNIST experiments and displays tables
def run_mnist_experiments(mnist_data_tuple):
    from IPython.display import display
    mnist_train, mnist_val, mnist_test = mnist_data_tuple
    in_channels = 1
    input_dim = 28 * 28

    mlp_presets = get_mlp_presets()
    cnn_presets = get_cnn_presets()

    for name, builder in mlp_presets.items():
        df, test_acc, cfg = run_random_search(
            "MNIST", name, builder,
            mnist_train, mnist_val, mnist_test,
            in_channels, EPOCHS_MNIST, NUM_TRIALS_PER_ARCH, REPEATS_PER_CONFIG, PATIENCE,
            is_mlp=True, input_dim=input_dim
        )
        display(df)
        print(f"[MNIST] {name} — Test accuracy: {test_acc:.4f}")

    for name, builder in cnn_presets.items():
        df, test_acc, cfg = run_random_search(
            "MNIST", name, builder,
            mnist_train, mnist_val, mnist_test,
            in_channels, EPOCHS_MNIST, NUM_TRIALS_PER_ARCH, REPEATS_PER_CONFIG, PATIENCE,
            is_mlp=False
        )
        display(df)
        print(f"[MNIST] {name} — Test accuracy: {test_acc:.4f}")

run_mnist_experiments(mnist_data)

# Function that runs all CIFAR-10 experiments and displays tables
def run_cifar_experiments(cifar_data_tuple):
    from IPython.display import display
    cifar_train, cifar_val, cifar_test = cifar_data_tuple
    in_channels = 3
    input_dim = 32 * 32 * 3

    mlp_presets = get_mlp_presets()
    cnn_presets = get_cnn_presets()

    for name, builder in mlp_presets.items():
        df, test_acc, cfg = run_random_search(
            "CIFAR10", name, builder,
            cifar_train, cifar_val, cifar_test,
            in_channels, EPOCHS_CIFAR, NUM_TRIALS_PER_ARCH, REPEATS_PER_CONFIG, PATIENCE,
            is_mlp=True, input_dim=input_dim
        )
        display(df)
        print(f"[CIFAR-10] {name} — Test accuracy: {test_acc:.4f}")

    for name, builder in cnn_presets.items():
        df, test_acc, cfg = run_random_search(
            "CIFAR10", name, builder,
            cifar_train, cifar_val, cifar_test,
            in_channels, EPOCHS_CIFAR, NUM_TRIALS_PER_ARCH, REPEATS_PER_CONFIG, PATIENCE,
            is_mlp=False
        )
        display(df)
        print(f"[CIFAR-10] {name} — Test accuracy: {test_acc:.4f}")

run_cifar_experiments(cifar_data)

"""### Results and Reporting
- **Validation Results:** Best validation configurations are summarized into concise CSV tables for MNIST and CIFAR-10, used to populate Tables 1 and 2 in the report.  
- **Final Test Results:** Test accuracies of retrained models are printed and recorded for final comparison.  
*(Ref: “For each dataset and architecture, present results in the format shown in Tables 1 and 2 … Clearly justify your final chosen model.”)*

"""

# Function that summarizes best validation rows and saves CSV
def summarize_best_tables(dataset_tag, arch_prefix):
    import pandas as pd, glob
    rows = []
    for path in glob.glob(os.path.join(RESULTS_DIR, f"{dataset_tag}_{arch_prefix}*_validation_results.csv")):
        df = pd.read_csv(path)
        best_row = df.iloc[df["Validation Acc"].argmax()]
        rows.append([
            best_row["Architecture"], best_row["Learning rate"], int(best_row["Batch size"]),
            best_row["Optimizer"], best_row["Dropout"],
            f'{best_row["Validation Acc"]:.4f}', f'{float(best_row["Runtime (min)"]):.2f}'
        ])
    if not rows:
        return None
    out_df = pd.DataFrame(rows, columns=["Architecture","Learning rate","Batch size","Optimizer","Dropout","Validation Acc (best)","Runtime (min)"])
    out_csv = os.path.join(RESULTS_DIR, f"{dataset_tag}_{arch_prefix}_summary.csv")
    out_df.to_csv(out_csv, index=False)
    return out_df, out_csv

print("MNIST summaries:")
print(summarize_best_tables("MNIST", "MLP"))
print(summarize_best_tables("MNIST", "CNN"))
print("CIFAR-10 summaries:")
print(summarize_best_tables("CIFAR10", "MLP"))
print(summarize_best_tables("CIFAR10", "CNN"))

# Function that prints final test accuracy reports per architecture
def print_final_reports(dataset_tag):
    import glob
    result_files = sorted(glob.glob(os.path.join(RESULTS_DIR, f"{dataset_tag}_*_final_test.json")))
    for fpath in result_files:
        with open(fpath, "r") as f:
            data = json.load(f)
        print(f'[{dataset_tag}] {data["architecture"]} — Best Val={data["best_val_acc"]:.4f} | Test={data["test_acc"]:.4f} | Best CFG={data["best_config"]}')

print_final_reports("MNIST")
print_final_reports("CIFAR10")
