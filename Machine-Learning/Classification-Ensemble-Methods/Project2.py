# -*- coding: utf-8 -*-
"""Project_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IKFqh9FpkgXMep5rCEITbAUpJSgbLt9_

# **Project 2 - Evaluation of Tree-Based Classifiers and Their Ensembles**

In this project, you will evaluate tree-based classifiers and their ensemble methods as discussed in class.
You will use scikit-learn and perform the following experiments:

1) Decision Tree Classifier
2) Bagging with Decision Trees
3) Random Forest Classifier
4) Gradient Boosting Classifier
5) Comparative Analysis


CS 6375.001 | Anil Lingala (akl180001)
"""

# Imports
import os, json, itertools, random
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, f1_score

#Experiment 1
import itertools
from sklearn.tree import DecisionTreeClassifier

#Experiment 2
from sklearn.ensemble import BaggingClassifier

#Experiment 3
from sklearn.ensemble import RandomForestClassifier

#Experiment 4
from sklearn.ensemble import GradientBoostingClassifier

#Experiment 5, 6
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split

# Installs dependencies and set paths
!pip -q install numpy pandas scikit-learn joblib

BASE_DIR = '/content/all_data'
OUT_DIR  = '/content/outputs_data'
SEED     = 42

MAX_TRIALS_PER_DATASET = 20
PATIENCE = 4

clause_counts = [300, 500, 1000, 1500, 1800]
data_sizes    = [100, 1000, 5000]
run_datasets = [(c, d) for c in clause_counts for d in data_sizes]

os.makedirs(OUT_DIR, exist_ok=True)
print("BASE_DIR:", BASE_DIR)
print("OUT_DIR :", OUT_DIR)
print("datasets:", len(run_datasets))

"""# **Datasets**

• Download the 15 datasets available on eLearning. Each dataset is divided into three subsets: the
training set, the validation set, and the test set.

The datasets are in CSV format, where each row
represents an instance with attribute values separated by commas. The last attribute corresponds to
the class variable.
"""

# function that loads train/valid/test for one (clauses, size)
def load_data(folder, clause_count, data_size):
    def read(split):
        path = os.path.join(folder, f"{split}_c{clause_count}_d{data_size}.csv")
        frame = pd.read_csv(path, header=None)
        features = frame.iloc[:, :-1].values.astype("float32", copy=False)
        labels   = frame.iloc[:, -1].values
        return features, labels
    train_data, train_labels = read("train")
    valid_data, valid_labels = read("valid")
    test_data,  test_labels  = read("test")
    return (train_data, train_labels), (valid_data, valid_labels), (test_data, test_labels)

# function that computes accuracy and f1
def compute_scores(true_labels, predicted_labels):
    return {"accuracy": accuracy_score(true_labels, predicted_labels),
            "f1": f1_score(true_labels, predicted_labels, average="binary")}

# function that returns random parameter combinations
def sample_param_combos(grid, max_trials, seed):
    keys = list(grid.keys())
    all_combos = [dict(zip(keys, vals)) for vals in itertools.product(*[grid[k] for k in keys])]
    random.seed(seed)
    random.shuffle(all_combos)
    return all_combos[:max_trials] if max_trials < len(all_combos) else all_combos

"""# **Decision Tree Classifier:**

Train a sklearn.tree.DecisionTreeClassifier
on each dataset.

Use the validation set to tune hyperparameters (e.g., criterion, splitter, max depth). After tuning, combine the training and validation sets, retrain with the best parameter settings, and
report:

  • Best hyperparameter settings found via tuning.

  • Classification accuracy and F1 score on the test set
"""

# function that tunes DecisionTree
def decision_tree(train_data, train_labels, valid_data, valid_labels, test_data, test_labels,
                            max_trials=20, patience=4):
    grid = {
        "criterion": ["gini", "entropy", "log_loss"],
        "max_depth": [None, 10, 20, 40],
        "min_samples_split": [2, 10, 50],
        "min_samples_leaf": [1, 5, 10],
        "random_state": [SEED]
    }
    combos = sample_param_combos(grid, max_trials, SEED)
    best_params, best_acc, no_improve = None, -1.0, 0
    for params in combos:
        model = DecisionTreeClassifier(**params)
        model.fit(train_data, train_labels)
        acc = model.score(valid_data, valid_labels)
        if acc > best_acc + 1e-6:
            best_params, best_acc, no_improve = params, acc, 0
        else:
            no_improve += 1
            if no_improve >= patience: break
    combined_X = np.vstack([train_data, valid_data])
    combined_y = np.concatenate([train_labels, valid_labels])
    final_model = DecisionTreeClassifier(**best_params)
    final_model.fit(combined_X, combined_y)
    preds = final_model.predict(test_data)
    return best_params, compute_scores(test_labels, preds)

out_csv = f"{OUT_DIR}/experiment1_decision_tree.csv"
rows, done = [], set()
if os.path.exists(out_csv):
    prev = pd.read_csv(out_csv)
    done = set(prev["dataset"].tolist())
    rows = prev.to_dict(orient="records")

for clause_count, data_size in run_datasets:
    tag = f"c{clause_count}_d{data_size}"
    if tag in done: print("skip:", tag); continue
    (tr, tr_y), (va, va_y), (te, te_y) = load_data(BASE_DIR, clause_count, data_size)
    best_params, scores = decision_tree(tr, tr_y, va, va_y, te, te_y,
                                                  MAX_TRIALS_PER_DATASET, PATIENCE)
    rows.append({"dataset": tag, "best_params": json.dumps(best_params),
                 "accuracy": scores["accuracy"], "f1": scores["f1"]})
    pd.DataFrame(rows).to_csv(out_csv, index=False)
    print(f"{tag} | acc={scores['accuracy']:.4f} | f1={scores['f1']:.4f}")
pd.DataFrame(rows)[["dataset","accuracy"]].to_csv(f"{OUT_DIR}/experiment1_accuracy.csv", index=False)
pd.DataFrame(rows)[["dataset","f1"]].to_csv(f"{OUT_DIR}/experiment1_f1.csv", index=False)

"""# **Bagging with Decision Trees:**

Repeat the above experiment using
sklearn.ensemble.BaggingClassifier with a DecisionTreeClassifier as the base
estimator. Report:

• Best hyperparameter settings found via tuning.

• Classification accuracy and F1 score.
"""

# Function that tunes Bagging with DecisionTree
def bagging_decision_tree(train_data, train_labels, valid_data, valid_labels, test_data, test_labels,
                               max_trials=20, patience=4):
    grid = {
        "n_estimators": [25, 50, 100],
        "max_samples": [0.5, 1.0],
        "max_features": [0.5, 1.0],
        "bootstrap": [True],
        "base_params": [
            {"criterion": "gini", "max_depth": None, "random_state": SEED},
            {"criterion": "entropy", "max_depth": None, "random_state": SEED}
        ]
    }
    combos = sample_param_combos(grid, max_trials, SEED)
    best_params, best_acc, no_improve = None, -1.0, 0
    for p in combos:
        base = DecisionTreeClassifier(**p["base_params"])
        model = BaggingClassifier(
            estimator=base, n_estimators=p["n_estimators"], max_samples=p["max_samples"],
            max_features=p["max_features"], bootstrap=p["bootstrap"], random_state=SEED, n_jobs=-1
        )
        model.fit(train_data, train_labels)
        acc = model.score(valid_data, valid_labels)
        if acc > best_acc + 1e-6:
            best_params = p; best_acc, no_improve = acc, 0
        else:
            no_improve += 1
            if no_improve >= patience: break
    combined_X = np.vstack([train_data, valid_data])
    combined_y = np.concatenate([train_labels, valid_labels])
    final_model = BaggingClassifier(
        estimator=DecisionTreeClassifier(**best_params["base_params"]),
        n_estimators=best_params["n_estimators"],
        max_samples=best_params["max_samples"],
        max_features=best_params["max_features"],
        bootstrap=best_params["bootstrap"],
        random_state=SEED, n_jobs=-1
    )
    final_model.fit(combined_X, combined_y)
    preds = final_model.predict(test_data)
    return best_params, compute_scores(test_labels, preds)

out_csv = f"{OUT_DIR}/experiment2_bagging.csv"
rows = []
for clause_count, data_size in run_datasets:
    tag = f"c{clause_count}_d{data_size}"
    (tr, tr_y), (va, va_y), (te, te_y) = load_data(BASE_DIR, clause_count, data_size)
    best_params, scores = bagging_decision_tree(tr, tr_y, va, va_y, te, te_y,
                                                     MAX_TRIALS_PER_DATASET, PATIENCE)
    rows.append({"dataset": tag, "best_params": json.dumps(best_params),
                 "accuracy": scores["accuracy"], "f1": scores["f1"]})
    print(f"{tag} | acc={scores['accuracy']:.4f} | f1={scores['f1']:.4f}")
pd.DataFrame(rows).to_csv(out_csv, index=False)
pd.DataFrame(rows)[["dataset","accuracy"]].to_csv(f"{OUT_DIR}/experiment2_accuracy.csv", index=False)
pd.DataFrame(rows)[["dataset","f1"]].to_csv(f"{OUT_DIR}/experiment2_f1.csv", index=False)

"""# **Random Forest Classifier:**

Repeat the experiment using
sklearn.ensemble.RandomForestClassifier. Report the best parameter settings, classification accuracy, and F1 score.
"""

# function that tunes RandomForest
def random_forest(train_data, train_labels, valid_data, valid_labels, test_data, test_labels,
                                     max_trials=20, patience=4):
    grid = {
        "n_estimators": [100, 200],
        "max_depth": [None, 20, 40],
        "min_samples_split": [2, 10],
        "min_samples_leaf": [1, 5],
        "max_features": ["sqrt", "log2", None],
        "bootstrap": [True],
        "random_state": [SEED],
        "n_jobs": [-1]
    }
    combos = sample_param_combos(grid, max_trials, SEED)
    best_params, best_acc, no_improve = None, -1.0, 0
    for params in combos:
        model = RandomForestClassifier(**params)
        model.fit(train_data, train_labels)
        acc = model.score(valid_data, valid_labels)
        if acc > best_acc + 1e-6:
            best_params, best_acc, no_improve = params, acc, 0
        else:
            no_improve += 1
            if no_improve >= patience: break
    combined_X = np.vstack([train_data, valid_data])
    combined_y = np.concatenate([train_labels, valid_labels])
    final_model = RandomForestClassifier(**best_params)
    final_model.fit(combined_X, combined_y)
    preds = final_model.predict(test_data)
    return best_params, compute_scores(test_labels, preds)

out_csv = f"{OUT_DIR}/experiment3_random_forest.csv"
rows, done = [], set()
if os.path.exists(out_csv):
    prev = pd.read_csv(out_csv)
    if "dataset" in prev.columns:
        done = set(prev["dataset"].astype(str).tolist())
        rows = prev.to_dict(orient="records")

for clause_count, data_size in run_datasets:
    tag = f"c{clause_count}_d{data_size}"
    if tag in done:
        print("skip:", tag);
        continue
    (tr, tr_y), (va, va_y), (te, te_y) = load_data(BASE_DIR, clause_count, data_size)
    best_params, scores = random_forest(
        tr, tr_y, va, va_y, te, te_y, MAX_TRIALS_PER_DATASET, PATIENCE
    )
    rows.append({
        "dataset": tag,
        "best_params": json.dumps(best_params),
        "accuracy": scores["accuracy"],
        "f1": scores["f1"]
    })
    pd.DataFrame(rows).to_csv(out_csv, index=False)
    print(f"{tag} | acc={scores['accuracy']:.4f} | f1={scores['f1']:.4f}")

pd.DataFrame(rows)[["dataset","accuracy"]].to_csv(f"{OUT_DIR}/experiment3_accuracy.csv", index=False)
pd.DataFrame(rows)[["dataset","f1"]].to_csv(f"{OUT_DIR}/experiment3_f1.csv", index=False)

"""# **Gradient Boosting Classifier:**

Repeat the experiment using
sklearn.ensemble.GradientBoostingClassifier. Report the best parameter settings,
classification accuracy, and F1 score
"""

# function that tunes GradientBoosting
def gradient_boosting(train_data, train_labels, valid_data, valid_labels, test_data, test_labels,
                                         max_trials=20, patience=4):
    grid = {
        "n_estimators": [100, 200],
        "learning_rate": [0.05, 0.1],
        "max_depth": [2, 3],
        "subsample": [1.0, 0.8],
        "min_samples_leaf": [1, 5],
        "max_features": [None, "sqrt"],
        "random_state": [SEED]
    }
    combos = sample_param_combos(grid, max_trials, SEED)
    best_params, best_acc, no_improve = None, -1.0, 0
    for params in combos:
        model = GradientBoostingClassifier(**params)
        model.fit(train_data, train_labels)
        acc = model.score(valid_data, valid_labels)
        if acc > best_acc + 1e-6:
            best_params, best_acc, no_improve = params, acc, 0
        else:
            no_improve += 1
            if no_improve >= patience: break
    combined_X = np.vstack([train_data, valid_data])
    combined_y = np.concatenate([train_labels, valid_labels])
    final_model = GradientBoostingClassifier(**best_params)
    final_model.fit(combined_X, combined_y)
    preds = final_model.predict(test_data)
    return best_params, compute_scores(test_labels, preds)

out_csv = f"{OUT_DIR}/experiment4_gradient_boosting.csv"
rows, done = [], set()
if os.path.exists(out_csv):
    prev = pd.read_csv(out_csv)
    if "dataset" in prev.columns:
        done = set(prev["dataset"].astype(str).tolist())
        rows = prev.to_dict(orient="records")

for clause_count, data_size in run_datasets:
    tag = f"c{clause_count}_d{data_size}"
    if tag in done:
        print("skip:", tag);
        continue
    (tr, tr_y), (va, va_y), (te, te_y) = load_data(BASE_DIR, clause_count, data_size)
    best_params, scores = gradient_boosting(
        tr, tr_y, va, va_y, te, te_y, MAX_TRIALS_PER_DATASET, PATIENCE
    )
    rows.append({
        "dataset": tag,
        "best_params": json.dumps(best_params),
        "accuracy": scores["accuracy"],
        "f1": scores["f1"]
    })
    pd.DataFrame(rows).to_csv(out_csv, index=False)
    print(f"{tag} | acc={scores['accuracy']:.4f} | f1={scores['f1']:.4f}")

pd.DataFrame(rows)[["dataset","accuracy"]].to_csv(f"{OUT_DIR}/experiment4_accuracy.csv", index=False)
pd.DataFrame(rows)[["dataset","f1"]].to_csv(f"{OUT_DIR}/experiment4_f1.csv", index=False)

"""# **Comparative Analysis:**

Record the classification accuracy and F1 scores for each testset
and classifier in a table. You can arrange all your results in a table shown above (Table 11). Make sure
you have two tables: one for classification accuracy and one for F1 Score.

Then answer the following
questions: (**Answers in report**)

• Which classifier achieves the best overall generalization accuracy/F1 score? Explain why.

• How does increasing the training data size impact accuracy/F1 score for each classifier?

• How does increasing the number of features (clauses) affect classifier performance?
"""

# function that merges accuracy/f1 tables from all classifiers
def combine_results():
    classifiers = {
        "DecisionTree": "experiment1_decision_tree",
        "Bagging": "experiment2_bagging",
        "RandomForest": "experiment3_random_forest",
        "GradientBoosting": "experiment4_gradient_boosting"
    }
    acc_df, f1_df = pd.DataFrame(), pd.DataFrame()
    for name, pref in classifiers.items():
        acc_path = os.path.join(OUT_DIR, f"{pref}_accuracy.csv")
        f1_path  = os.path.join(OUT_DIR, f"{pref}_f1.csv")
        if os.path.exists(acc_path):
            acc = pd.read_csv(acc_path).rename(columns={"accuracy": name})
            acc_df = acc if acc_df.empty else acc_df.merge(acc, on="dataset", how="outer")
        if os.path.exists(f1_path):
            f1 = pd.read_csv(f1_path).rename(columns={"f1": name})
            f1_df = f1 if f1_df.empty else f1_df.merge(f1, on="dataset", how="outer")
    acc_df.to_csv(f"{OUT_DIR}/experiment5_accuracy_table.csv", index=False)
    f1_df.to_csv(f"{OUT_DIR}/experiment5_f1_table.csv", index=False)
    return acc_df, f1_df

accuracy_table, f1_table = combine_results()
display(accuracy_table.head())
display(f1_table.head())

"""# **MNIST dataset**

The MNIST dataset consists of a training set of 60,000 examples and a test set of 10,000 examples. Each digit is centered within a 28×28 pixel grayscale image.

Evaluate the four classifiers used earlier—**Decision Trees, Bagging, Random Forest, and Gradient Boosting**—on the MNIST dataset. Report their classification accuracy (do not compute F1
scores).

"""

# function that downloads and splits MNIST, then trains 4 models
def load_mnist():
    data, labels = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)
    data   = data.astype('float32') / 255.0
    labels = labels.astype('int64')
    return (data[:60000], labels[:60000]), (data[60000:], labels[60000:])

def run_mnist_models(train_data, train_labels, test_data, test_labels, seed):
    models = {
        "DecisionTree": DecisionTreeClassifier(random_state=seed, max_depth=None),
        "Bagging": BaggingClassifier(
            estimator=DecisionTreeClassifier(random_state=seed, max_depth=None),
            n_estimators=50, random_state=seed, n_jobs=-1
        ),
        "RandomForest": RandomForestClassifier(
            n_estimators=200, max_depth=None, random_state=seed, n_jobs=-1
        ),
        "GradientBoosting": GradientBoostingClassifier(random_state=seed)
    }
    rows = []
    for name, model in models.items():
        model.fit(train_data, train_labels)
        preds = model.predict(test_data)
        acc = float(accuracy_score(test_labels, preds))
        rows.append({"model": name, "accuracy": acc})
        print(f"{name}: accuracy={acc:.4f}")
    out = pd.DataFrame(rows).sort_values("accuracy", ascending=False)
    out.to_csv(f"{OUT_DIR}/mnist_results.csv", index=False)
    return out

(train_data, train_labels), (test_data, test_labels) = load_mnist()
mnist_results = run_mnist_models(train_data, train_labels, test_data, test_labels, SEED)
mnist_results